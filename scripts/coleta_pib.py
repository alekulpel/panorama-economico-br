# scripts/coleta_contas_nacionais.py (ou nome que preferir)

print("ðŸš€ Iniciando script de coleta de dados das Contas Nacionais Trimestrais (SIDRA Tabela 6613)...")

import requests
import pandas as pd
import os
import logging

# ConfiguraÃ§Ã£o do Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- ParÃ¢metros da Consulta ---
TABLE_ID = "6613"
GEO_LEVEL = "n1"
GEO_CODE = "1" # Brasil
VARIABLES = "all"
PERIODS = "all"
CLASSIFICATION = "c11255"
CATEGORIES = "all"
FORMAT_CODE = "v9319%202"

api_url = f"https://apisidra.ibge.gov.br/values/t/{TABLE_ID}/{GEO_LEVEL}/{GEO_CODE}/v/{VARIABLES}/p/{PERIODS}/{CLASSIFICATION}/{CATEGORIES}/d/{FORMAT_CODE}"

output_dir = "/home/akulpel/Projetos/panorama-economico-br/data/raw"
output_file = os.path.join(output_dir, "cnt_6613_setorial_dessazonalizado_bruto.csv")

def coleta_dados_sidra(url, filename):
    logging.info(f"Iniciando coleta da URL: {url}")
    try:
        response = requests.get(url, verify=True, timeout=90)
        response.raise_for_status()
        logging.info(f"âœ… ConexÃ£o bem-sucedida! Status: {response.status_code}")
        dados_json = response.json()

        if not dados_json or len(dados_json) <= 1:
            logging.warning("âš ï¸ A API retornou dados vazios ou apenas o cabeÃ§alho.")
            return

        logging.info(f"ðŸ” Exemplo de dado retornado (primeiro registro): {dados_json[1]}")

        header_map = dados_json[0]
        internal_codes = list(dados_json[1].keys())
        colunas_legiveis = [header_map.get(code, code) for code in internal_codes]
        dados_limpos = [list(item.values()) for item in dados_json[1:]]
        df = pd.DataFrame(dados_limpos, columns=colunas_legiveis)

        logging.info(f"ðŸ“Š DataFrame criado com {df.shape[0]} linhas e {df.shape[1]} colunas.")
        logging.info(f"Colunas originais: {df.columns.tolist()}")

        # --- Limpeza BÃ¡sica (AJUSTADA para incluir todas as colunas identificadas) ---
        rename_map = {
            'NÃ­vel Territorial (CÃ³digo)': 'nivel_territorial_cod', # Adicionado
            'NÃ­vel Territorial': 'nivel_territorial_nome',     # Adicionado
            'Unidade de Medida (CÃ³digo)': 'unidade_medida_cod', # Adicionado
            'Unidade de Medida': 'unidade_medida_nome',      # Adicionado
            'Valor': 'valor',
            'Trimestre (CÃ³digo)': 'trimestre_codigo',
            'Trimestre': 'trimestre_nome',
            'Brasil (CÃ³digo)': 'geo_cod', # Confirmado que existe
            'Brasil': 'geo_nome',       # Confirmado que existe
            'Setores e subsetores (CÃ³digo)': 'setor_cod',
            'Setores e subsetores': 'setor_nome',
            'VariÃ¡vel (CÃ³digo)': 'variavel_cod',
            'VariÃ¡vel': 'variavel_nome'
        }
        df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns}, inplace=True)
        logging.info(f"Colunas apÃ³s renomear: {df.columns.tolist()}")

        # Converter 'valor' para numÃ©rico
        if 'valor' in df.columns:
            df['valor'] = df['valor'].replace({'...': pd.NA, '-': pd.NA, 'X': pd.NA}, regex=False)
            df['valor'] = pd.to_numeric(df['valor'], errors='coerce')
            logging.info("Coluna 'valor' convertida para numÃ©rico.")

        # Tratar perÃ­odo trimestral
        if 'trimestre_codigo' in df.columns:
            try:
                df['ano'] = df['trimestre_codigo'].str[:4].astype(int)
                df['trimestre_num'] = df['trimestre_codigo'].str[4:].astype(int)
                df['periodo_trimestral'] = pd.PeriodIndex(year=df['ano'], quarter=df['trimestre_num'], freq='Q')
                logging.info("Colunas 'ano', 'trimestre_num', 'periodo_trimestral' criadas.")

                # --- Opcional: Remover colunas redundantes ---
                # ApÃ³s criar 'periodo_trimestral', as colunas usadas para criÃ¡-la
                # podem nÃ£o ser mais necessÃ¡rias para a anÃ¡lise.
                cols_to_drop = ['trimestre_codigo', 'trimestre_nome', 'ano', 'trimestre_num']
                # Remove apenas as colunas que existem no DataFrame
                cols_existentes_para_dropar = [col for col in cols_to_drop if col in df.columns]
                if cols_existentes_para_dropar:
                     df.drop(columns=cols_existentes_para_dropar, inplace=True)
                     logging.info(f"Colunas redundantes removidas: {cols_existentes_para_dropar}")

            except Exception as e:
                logging.warning(f"NÃ£o foi possÃ­vel converter 'trimestre_codigo' ou remover colunas: {e}")


        # Garantir que o diretÃ³rio de saÃ­da exista
        os.makedirs(output_dir, exist_ok=True)
        df.to_csv(output_file, index=False, encoding='utf-8')
        logging.info(f"âœ… Dados brutos (com limpeza bÃ¡sica) salvos em: {output_file}")

    except requests.exceptions.SSLError as e:
         logging.error(f"âŒ Erro de SSL: {e}. Verifique certificados ou tente 'verify=False'.")
    except requests.exceptions.RequestException as e:
        logging.error(f"âŒ Erro de conexÃ£o com a API: {e}")
    except ValueError as e:
        response_text = "N/A (response nÃ£o definido)"
        try: response_text = response.text[:500]
        except NameError: pass
        logging.error(f"âŒ Erro ao processar JSON da API: {e} - ConteÃºdo inicial: {response_text}")
    except Exception as e:
        logging.error(f"âŒ Erro inesperado durante a coleta: {e}", exc_info=True)

# --- ExecuÃ§Ã£o ---
if __name__ == "__main__":
    print(f"URL da API que serÃ¡ usada:\n{api_url}")
    print(f"Os dados serÃ£o salvos em: {os.path.abspath(output_file)}")
    # input("Pressione Enter para continuar...") # Pausa opcional

    coleta_dados_sidra(api_url, output_file)
    print(f"âœ… Script de coleta da SIDRA ({os.path.basename(__file__)}) finalizado.")